name: Sync Analytics Data

on:
  schedule:
    # Run every Monday at midnight UTC (weekly)
    - cron: '0 0 * * 1'
  workflow_dispatch: # Allow manual triggering

jobs:
  sync-analytics:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Fetch visit data from Netlify
        id: fetch-data
        env:
          NETLIFY_URL: ${{ secrets.NETLIFY_SITE_URL }}
          EXPORT_TOKEN: ${{ secrets.NETLIFY_EXPORT_TOKEN }}
        run: |
          python3 << 'EOF'
          import json
          import os
          import urllib.request
          
          netlify_url = os.environ.get('NETLIFY_URL', 'https://remarkable-syrniki-5c721e.netlify.app')
          export_token = os.environ.get('EXPORT_TOKEN', '')
          
          # Ensure URL doesn't have trailing slash
          netlify_url = netlify_url.rstrip('/')
          
          # Fetch visit data from Netlify function
          url = f"{netlify_url}/.netlify/functions/export-visits"
          if export_token:
              url += f"?token={export_token}"
          
          print(f"Fetching data from: {url}")
          
          try:
              req = urllib.request.Request(url)
              with urllib.request.urlopen(req) as response:
                  data = json.loads(response.read().decode())
                  
              # Save to file
              with open('visits-export.json', 'w') as f:
                  json.dump(data, f, indent=2)
              
              visits = data.get('visits', [])
              print(f"Fetched {len(visits)} visits from Netlify")
          except Exception as e:
              print(f"Error fetching data: {e}")
              import traceback
              traceback.print_exc()
              # Create empty data structure
              with open('visits-export.json', 'w') as f:
                  json.dump({'visits': [], 'total': 0}, f)
          EOF

      - name: Aggregate analytics data
        run: |
          python3 << 'EOF'
          import json
          import os
          from collections import defaultdict
          from datetime import datetime
          
          # Read visits from export
          with open('visits-export.json', 'r') as f:
              export_data = json.load(f)
          
          visits = export_data.get('visits', [])
          
          if not visits:
              print("No visits to aggregate")
              stats = {
                  "totalVisits": 0,
                  "visitsByCountry": {},
                  "visitsByRegion": {},
                  "timeline": [],
                  "visits": [],
                  "lastUpdated": datetime.now().isoformat()
              }
          else:
              # Aggregate by country
              country_counts = defaultdict(int)
              for visit in visits:
                  country = visit.get('country', 'Unknown')
                  country_counts[country] += 1
              
              # Aggregate by region
              region_counts = defaultdict(int)
              for visit in visits:
                  country = visit.get('country')
                  region = visit.get('region')
                  if country and region:
                      region_key = f"{region}, {country}"
                      region_counts[region_key] += 1
              
              # Create timeline (group by day)
              timeline_dict = defaultdict(int)
              for visit in visits:
                  timestamp = visit.get('timestamp', '')
                  if timestamp:
                      date = timestamp.split('T')[0]
                      timeline_dict[date] += 1
              
              timeline = [{"date": date, "count": count} 
                         for date, count in sorted(timeline_dict.items())]
              
              # Create aggregated stats object
              stats = {
                  "totalVisits": len(visits),
                  "visitsByCountry": dict(country_counts),
                  "visitsByRegion": dict(region_counts),
                  "timeline": timeline,
                  "visits": visits,
                  "lastUpdated": datetime.now().isoformat()
              }
          
          # Ensure assets/data directory exists
          os.makedirs('assets/data', exist_ok=True)
          
          # Write to data file (in assets/data so it's served as static file)
          with open('assets/data/analytics-stats.json', 'w') as f:
              json.dump(stats, f, indent=2)
          
          print(f"Aggregated {stats['totalVisits']} visits")
          print(f"Countries: {len(stats['visitsByCountry'])}")
          print(f"Regions: {len(stats['visitsByRegion'])}")
          EOF

      - name: Commit and push changes
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add assets/data/analytics-stats.json
          if ! git diff --staged --quiet; then
            git commit -m "Update analytics data [skip ci]"
            git push
          else
            echo "No changes to commit"
          fi

